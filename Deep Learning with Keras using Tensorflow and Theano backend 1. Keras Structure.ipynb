{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts and Implementation of Deep learning in Python - Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy >= 0.17.0\n",
    "\n",
    "Numpy >= 1.11.0\n",
    "\n",
    "Matplotlib >= 1.5.1\n",
    "\n",
    "Pandas >= 0.18.0\n",
    "\n",
    "Scikit-learn >= 0.17.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy == 1.4.1\n",
      "pandas == 0.25.3\n",
      "numpy == 1.16.2\n",
      "scikit-learn == 0.20.2\n",
      "matplotlib == 3.0.2\n"
     ]
    }
   ],
   "source": [
    "# Verifying the module versions\n",
    "print('scipy == {}'.format(sc.__version__))\n",
    "print('pandas == {}'.format(pd.__version__))\n",
    "print('numpy == {}'.format(np.__version__))\n",
    "print('scikit-learn == {}'.format(sk.__version__))\n",
    "print('matplotlib == {}'.format(mpl.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 20.0.2 from /home/michael/.local/lib/python3.7/site-packages/pip (python 3.7)\r\n"
     ]
    }
   ],
   "source": [
    "# Python version\n",
    "!pip3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install theano for deep learning\n",
    "!pip install Theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with theano library\n",
    "import theano\n",
    "from theano import tensor\n",
    "# declare two symbolic floating-point scalars\n",
    "a = tensor.dscalar()\n",
    "b = tensor.dscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# Create a simple symbolic expression\n",
    "c = a + b\n",
    "# convert the expression into a callable object that takes a and b and computes c.\n",
    "f = theano.function([a, b], c)\n",
    "# create the inputs to calculate\n",
    "result = f(1.5, 2.5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(a, b):\n",
    "    c = a + b\n",
    "    return c\n",
    "f(1.5, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Tensorflow\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using tensorflow library.\n",
    "# declare symbolic floating-point scalars\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "# create a simple symbolic expression\n",
    "add = tf.add(a, b)\n",
    "# bind values to a and b\n",
    "sess = tf.Session()\n",
    "bind = {a: 1.5, b : 2.5}\n",
    "c = sess.run(add, feed_dict=bind)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the backend to any of Tensorflow or Theano to leverage on their computational properties while using the minimalist Keras API.\n",
    "\n",
    "Simply search for the directory ~/.keras/ and edit the backend property in the keras.json file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_pred = Activation(W0 + W1*X1 + .....+ Wn*Xn)\n",
    "\n",
    "initialize w0\n",
    "\n",
    "w0*X1 = yhat\n",
    "\n",
    "a = derivative(yhat-y)\n",
    "\n",
    "w1 = w - a*learn_rate\n",
    "\n",
    "w1*X2 = yhat2\n",
    "\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "wn\n",
    "\n",
    "new test\n",
    "\n",
    "wn*X = y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to design your Neural Network model\n",
    "1. Load Data.\n",
    "2. Define Model.\n",
    "3. Compile Model.\n",
    "4. Fit Model.\n",
    "5. Evaluate Model.\n",
    "6. Tie It All Together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-26 19:29:58--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.172.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.172.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23278 (23K) [text/plain]\n",
      "Saving to: ‘pima-indians-diabetes.data.csv’\n",
      "\n",
      "pima-indians-diabet 100%[===================>]  22.73K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2020-02-26 19:29:59 (279 KB/s) - ‘pima-indians-diabetes.data.csv’ saved [23278/23278]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's get an already cleaned dataset from the github repo.\n",
    "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Deep Learning With Tensorflow, Keras, Theano, Python.ipynb'\r\n",
      "'Linear Algebra and Basics Mathematics..ipynb'\r\n",
      " pima-indians-diabetes.data.csv\r\n"
     ]
    }
   ],
   "source": [
    "# List the files in your current directory\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful modules for neural networks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of times pregnant.\n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test.\n",
    "3. Diastolic blood pressure (mm Hg).\n",
    "4. Triceps skin fold thickness (mm).\n",
    "5. 2-Hour serum insulin (mu U/ml).\n",
    "6. Body mass index.\n",
    "7. Diabetes pedigree function.\n",
    "8. Age (years).\n",
    "9. Class, onset of diabetes within five years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify your random initialization\n",
    "np.random.randint(1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768, 8), (768,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input(X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sequential() # Call the keras sequential function, then add layers\n",
    "model.add(Dense(12, input_dim = 8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of trainable parameters:\n",
    "\n",
    "    = connections between layers + biases in every layer\n",
    "    = (8 * 12 + 12 * 8 + 8 * 1) + (12 + 8 + 1)\n",
    "    = 221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the model we have designed\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "768/768 [==============================] - 0s 133us/step - loss: 0.4409 - accuracy: 0.7747\n",
      "Epoch 2/200\n",
      "330/768 [===========>..................] - ETA: 0s - loss: 0.4272 - accuracy: 0.8061"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 150us/step - loss: 0.4453 - accuracy: 0.7865\n",
      "Epoch 3/200\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4424 - accuracy: 0.7865\n",
      "Epoch 4/200\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4394 - accuracy: 0.7773\n",
      "Epoch 5/200\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4539 - accuracy: 0.7839\n",
      "Epoch 6/200\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.4392 - accuracy: 0.7943\n",
      "Epoch 7/200\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4352 - accuracy: 0.7969\n",
      "Epoch 8/200\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4373 - accuracy: 0.7891\n",
      "Epoch 9/200\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4393 - accuracy: 0.7969\n",
      "Epoch 10/200\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.4385 - accuracy: 0.7891\n",
      "Epoch 11/200\n",
      "768/768 [==============================] - 0s 140us/step - loss: 0.4413 - accuracy: 0.7982\n",
      "Epoch 12/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.4395 - accuracy: 0.8047\n",
      "Epoch 13/200\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4345 - accuracy: 0.8021\n",
      "Epoch 14/200\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.4405 - accuracy: 0.7904\n",
      "Epoch 15/200\n",
      "768/768 [==============================] - 0s 178us/step - loss: 0.4368 - accuracy: 0.8047\n",
      "Epoch 16/200\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4371 - accuracy: 0.7982\n",
      "Epoch 17/200\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4361 - accuracy: 0.7865\n",
      "Epoch 18/200\n",
      "768/768 [==============================] - 0s 137us/step - loss: 0.4403 - accuracy: 0.7943\n",
      "Epoch 19/200\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.4363 - accuracy: 0.7891\n",
      "Epoch 20/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4201 - accuracy: 0.8060\n",
      "Epoch 21/200\n",
      "768/768 [==============================] - 0s 171us/step - loss: 0.4354 - accuracy: 0.8034\n",
      "Epoch 22/200\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4277 - accuracy: 0.8008\n",
      "Epoch 23/200\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4260 - accuracy: 0.8034\n",
      "Epoch 24/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.4282 - accuracy: 0.7930\n",
      "Epoch 25/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.4345 - accuracy: 0.8021\n",
      "Epoch 26/200\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.4295 - accuracy: 0.7917\n",
      "Epoch 27/200\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.4331 - accuracy: 0.7969\n",
      "Epoch 28/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4305 - accuracy: 0.8086\n",
      "Epoch 29/200\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.4283 - accuracy: 0.7956\n",
      "Epoch 30/200\n",
      "768/768 [==============================] - 0s 137us/step - loss: 0.4430 - accuracy: 0.7852\n",
      "Epoch 31/200\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.4385 - accuracy: 0.7969\n",
      "Epoch 32/200\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4273 - accuracy: 0.8073\n",
      "Epoch 33/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4278 - accuracy: 0.7969\n",
      "Epoch 34/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4204 - accuracy: 0.8099\n",
      "Epoch 35/200\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.4302 - accuracy: 0.8021\n",
      "Epoch 36/200\n",
      "768/768 [==============================] - 0s 116us/step - loss: 0.4275 - accuracy: 0.7812\n",
      "Epoch 37/200\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4277 - accuracy: 0.7995\n",
      "Epoch 38/200\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4251 - accuracy: 0.8060\n",
      "Epoch 39/200\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4249 - accuracy: 0.7956\n",
      "Epoch 40/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4199 - accuracy: 0.8034\n",
      "Epoch 41/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4230 - accuracy: 0.8099\n",
      "Epoch 42/200\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4222 - accuracy: 0.7969\n",
      "Epoch 43/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4171 - accuracy: 0.8099\n",
      "Epoch 44/200\n",
      "768/768 [==============================] - 0s 125us/step - loss: 0.4244 - accuracy: 0.7982\n",
      "Epoch 45/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4224 - accuracy: 0.8099\n",
      "Epoch 46/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.4185 - accuracy: 0.8073\n",
      "Epoch 47/200\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4298 - accuracy: 0.7956\n",
      "Epoch 48/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4284 - accuracy: 0.8021\n",
      "Epoch 49/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4206 - accuracy: 0.8138\n",
      "Epoch 50/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.4168 - accuracy: 0.8034\n",
      "Epoch 51/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4287 - accuracy: 0.7930\n",
      "Epoch 52/200\n",
      "768/768 [==============================] - 0s 144us/step - loss: 0.4227 - accuracy: 0.7930\n",
      "Epoch 53/200\n",
      "768/768 [==============================] - 0s 180us/step - loss: 0.4165 - accuracy: 0.8086\n",
      "Epoch 54/200\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.4273 - accuracy: 0.8047\n",
      "Epoch 55/200\n",
      "768/768 [==============================] - 0s 166us/step - loss: 0.4186 - accuracy: 0.8073\n",
      "Epoch 56/200\n",
      "768/768 [==============================] - 0s 242us/step - loss: 0.4210 - accuracy: 0.8060\n",
      "Epoch 57/200\n",
      "768/768 [==============================] - 0s 179us/step - loss: 0.4229 - accuracy: 0.8073\n",
      "Epoch 58/200\n",
      "768/768 [==============================] - 0s 147us/step - loss: 0.4143 - accuracy: 0.8086\n",
      "Epoch 59/200\n",
      "768/768 [==============================] - 0s 148us/step - loss: 0.4164 - accuracy: 0.8099\n",
      "Epoch 60/200\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.4141 - accuracy: 0.8177\n",
      "Epoch 61/200\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4154 - accuracy: 0.8099\n",
      "Epoch 62/200\n",
      "768/768 [==============================] - 0s 129us/step - loss: 0.4146 - accuracy: 0.8203\n",
      "Epoch 63/200\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.4192 - accuracy: 0.8047\n",
      "Epoch 64/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4197 - accuracy: 0.8086\n",
      "Epoch 65/200\n",
      "768/768 [==============================] - 0s 145us/step - loss: 0.4112 - accuracy: 0.8125\n",
      "Epoch 66/200\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4318 - accuracy: 0.7904\n",
      "Epoch 67/200\n",
      "768/768 [==============================] - 0s 128us/step - loss: 0.4179 - accuracy: 0.8008\n",
      "Epoch 68/200\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.4101 - accuracy: 0.8112\n",
      "Epoch 69/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.4134 - accuracy: 0.8190\n",
      "Epoch 70/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4096 - accuracy: 0.8073\n",
      "Epoch 71/200\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.4196 - accuracy: 0.8073\n",
      "Epoch 72/200\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4153 - accuracy: 0.8008\n",
      "Epoch 73/200\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.4146 - accuracy: 0.8125\n",
      "Epoch 74/200\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4098 - accuracy: 0.8125\n",
      "Epoch 75/200\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.4247 - accuracy: 0.7930\n",
      "Epoch 76/200\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.4128 - accuracy: 0.8177\n",
      "Epoch 77/200\n",
      "768/768 [==============================] - 0s 131us/step - loss: 0.4094 - accuracy: 0.8086\n",
      "Epoch 78/200\n",
      "768/768 [==============================] - 0s 136us/step - loss: 0.4037 - accuracy: 0.8125\n",
      "Epoch 79/200\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.4125 - accuracy: 0.8099\n",
      "Epoch 80/200\n",
      "768/768 [==============================] - 0s 130us/step - loss: 0.4062 - accuracy: 0.8203\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 100us/step - loss: 0.4167 - accuracy: 0.8112\n",
      "Epoch 82/200\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.4135 - accuracy: 0.8112\n",
      "Epoch 83/200\n",
      "768/768 [==============================] - 0s 123us/step - loss: 0.4113 - accuracy: 0.8099\n",
      "Epoch 84/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4098 - accuracy: 0.8060\n",
      "Epoch 85/200\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.4188 - accuracy: 0.8060\n",
      "Epoch 86/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4068 - accuracy: 0.8138\n",
      "Epoch 87/200\n",
      "768/768 [==============================] - 0s 120us/step - loss: 0.4066 - accuracy: 0.8125\n",
      "Epoch 88/200\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4384 - accuracy: 0.7852\n",
      "Epoch 89/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4202 - accuracy: 0.8034\n",
      "Epoch 90/200\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.4099 - accuracy: 0.8008\n",
      "Epoch 91/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.4064 - accuracy: 0.8125\n",
      "Epoch 92/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.4219 - accuracy: 0.8073\n",
      "Epoch 93/200\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4111 - accuracy: 0.8086\n",
      "Epoch 94/200\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.4171 - accuracy: 0.7982\n",
      "Epoch 95/200\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4114 - accuracy: 0.8047\n",
      "Epoch 96/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4083 - accuracy: 0.8255\n",
      "Epoch 97/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.4002 - accuracy: 0.8086\n",
      "Epoch 98/200\n",
      "768/768 [==============================] - 0s 90us/step - loss: 0.4109 - accuracy: 0.8151\n",
      "Epoch 99/200\n",
      "768/768 [==============================] - 0s 86us/step - loss: 0.4173 - accuracy: 0.8112\n",
      "Epoch 100/200\n",
      "768/768 [==============================] - 0s 85us/step - loss: 0.4028 - accuracy: 0.8216\n",
      "Epoch 101/200\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.4004 - accuracy: 0.8151\n",
      "Epoch 102/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.4026 - accuracy: 0.8125\n",
      "Epoch 103/200\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.4030 - accuracy: 0.8099\n",
      "Epoch 104/200\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.4052 - accuracy: 0.8216\n",
      "Epoch 105/200\n",
      "768/768 [==============================] - 0s 82us/step - loss: 0.4069 - accuracy: 0.8164\n",
      "Epoch 106/200\n",
      "768/768 [==============================] - 0s 84us/step - loss: 0.4037 - accuracy: 0.8073\n",
      "Epoch 107/200\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.4035 - accuracy: 0.8060\n",
      "Epoch 108/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.4046 - accuracy: 0.8138\n",
      "Epoch 109/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.4129 - accuracy: 0.8177\n",
      "Epoch 110/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.4114 - accuracy: 0.7904\n",
      "Epoch 111/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4138 - accuracy: 0.8086\n",
      "Epoch 112/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.4059 - accuracy: 0.8177\n",
      "Epoch 113/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.3994 - accuracy: 0.8099\n",
      "Epoch 114/200\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.4058 - accuracy: 0.8138\n",
      "Epoch 115/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4031 - accuracy: 0.8047\n",
      "Epoch 116/200\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.4107 - accuracy: 0.8164\n",
      "Epoch 117/200\n",
      "768/768 [==============================] - 0s 138us/step - loss: 0.4039 - accuracy: 0.8151\n",
      "Epoch 118/200\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.4089 - accuracy: 0.8190\n",
      "Epoch 119/200\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.4018 - accuracy: 0.8164\n",
      "Epoch 120/200\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.4034 - accuracy: 0.8164\n",
      "Epoch 121/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4035 - accuracy: 0.8086\n",
      "Epoch 122/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4023 - accuracy: 0.8151\n",
      "Epoch 123/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4167 - accuracy: 0.8060\n",
      "Epoch 124/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4050 - accuracy: 0.8190\n",
      "Epoch 125/200\n",
      "768/768 [==============================] - 0s 118us/step - loss: 0.4142 - accuracy: 0.8073\n",
      "Epoch 126/200\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.4108 - accuracy: 0.8060\n",
      "Epoch 127/200\n",
      "768/768 [==============================] - 0s 121us/step - loss: 0.3927 - accuracy: 0.8177\n",
      "Epoch 128/200\n",
      "768/768 [==============================] - 0s 119us/step - loss: 0.3961 - accuracy: 0.8164\n",
      "Epoch 129/200\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.4001 - accuracy: 0.8229\n",
      "Epoch 130/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4127 - accuracy: 0.8151\n",
      "Epoch 131/200\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.3940 - accuracy: 0.8164\n",
      "Epoch 132/200\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.3963 - accuracy: 0.8229\n",
      "Epoch 133/200\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.3979 - accuracy: 0.8164\n",
      "Epoch 134/200\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.3966 - accuracy: 0.8099\n",
      "Epoch 135/200\n",
      "768/768 [==============================] - 0s 86us/step - loss: 0.4011 - accuracy: 0.8164\n",
      "Epoch 136/200\n",
      "768/768 [==============================] - 0s 86us/step - loss: 0.3954 - accuracy: 0.8086\n",
      "Epoch 137/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4011 - accuracy: 0.8099\n",
      "Epoch 138/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.3896 - accuracy: 0.8190\n",
      "Epoch 139/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4056 - accuracy: 0.8151\n",
      "Epoch 140/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4202 - accuracy: 0.7956\n",
      "Epoch 141/200\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.3962 - accuracy: 0.8060\n",
      "Epoch 142/200\n",
      "768/768 [==============================] - 0s 80us/step - loss: 0.4147 - accuracy: 0.8164\n",
      "Epoch 143/200\n",
      "768/768 [==============================] - 0s 76us/step - loss: 0.3991 - accuracy: 0.8151\n",
      "Epoch 144/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.4018 - accuracy: 0.8073\n",
      "Epoch 145/200\n",
      "768/768 [==============================] - 0s 77us/step - loss: 0.3992 - accuracy: 0.8203\n",
      "Epoch 146/200\n",
      "768/768 [==============================] - 0s 80us/step - loss: 0.3972 - accuracy: 0.8138\n",
      "Epoch 147/200\n",
      "768/768 [==============================] - 0s 80us/step - loss: 0.4004 - accuracy: 0.8216\n",
      "Epoch 148/200\n",
      "768/768 [==============================] - 0s 76us/step - loss: 0.4078 - accuracy: 0.8125\n",
      "Epoch 149/200\n",
      "768/768 [==============================] - 0s 74us/step - loss: 0.4088 - accuracy: 0.8099\n",
      "Epoch 150/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.4089 - accuracy: 0.8203\n",
      "Epoch 151/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.4008 - accuracy: 0.8060\n",
      "Epoch 152/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.3980 - accuracy: 0.8203\n",
      "Epoch 153/200\n",
      "768/768 [==============================] - 0s 79us/step - loss: 0.3959 - accuracy: 0.8216\n",
      "Epoch 154/200\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.3977 - accuracy: 0.8164\n",
      "Epoch 155/200\n",
      "768/768 [==============================] - 0s 78us/step - loss: 0.3977 - accuracy: 0.8112\n",
      "Epoch 156/200\n",
      "768/768 [==============================] - 0s 78us/step - loss: 0.3966 - accuracy: 0.8099\n",
      "Epoch 157/200\n",
      "768/768 [==============================] - 0s 78us/step - loss: 0.4005 - accuracy: 0.8177\n",
      "Epoch 158/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.3971 - accuracy: 0.8164\n",
      "Epoch 159/200\n",
      "768/768 [==============================] - 0s 73us/step - loss: 0.3940 - accuracy: 0.8203\n",
      "Epoch 160/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.4013 - accuracy: 0.8151\n",
      "Epoch 161/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.3969 - accuracy: 0.8190\n",
      "Epoch 162/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.4006 - accuracy: 0.8099\n",
      "Epoch 163/200\n",
      "768/768 [==============================] - 0s 76us/step - loss: 0.4026 - accuracy: 0.8047\n",
      "Epoch 164/200\n",
      "768/768 [==============================] - 0s 75us/step - loss: 0.3876 - accuracy: 0.8242\n",
      "Epoch 165/200\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.3966 - accuracy: 0.8151\n",
      "Epoch 166/200\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.3938 - accuracy: 0.8281\n",
      "Epoch 167/200\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.4148 - accuracy: 0.8151\n",
      "Epoch 168/200\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.3983 - accuracy: 0.8242\n",
      "Epoch 169/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.4006 - accuracy: 0.8125\n",
      "Epoch 170/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.3912 - accuracy: 0.8281\n",
      "Epoch 171/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.4001 - accuracy: 0.8151\n",
      "Epoch 172/200\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.3958 - accuracy: 0.8164\n",
      "Epoch 173/200\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.3965 - accuracy: 0.8151\n",
      "Epoch 174/200\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.3895 - accuracy: 0.8216\n",
      "Epoch 175/200\n",
      "768/768 [==============================] - 0s 132us/step - loss: 0.3973 - accuracy: 0.8255\n",
      "Epoch 176/200\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.3971 - accuracy: 0.8151\n",
      "Epoch 177/200\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.4080 - accuracy: 0.8229\n",
      "Epoch 178/200\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.3904 - accuracy: 0.8190\n",
      "Epoch 179/200\n",
      "768/768 [==============================] - 0s 83us/step - loss: 0.3946 - accuracy: 0.8151\n",
      "Epoch 180/200\n",
      "768/768 [==============================] - 0s 81us/step - loss: 0.3999 - accuracy: 0.8086\n",
      "Epoch 181/200\n",
      "768/768 [==============================] - 0s 151us/step - loss: 0.3937 - accuracy: 0.8177\n",
      "Epoch 182/200\n",
      "768/768 [==============================] - 0s 193us/step - loss: 0.3910 - accuracy: 0.8164\n",
      "Epoch 183/200\n",
      "768/768 [==============================] - 0s 168us/step - loss: 0.3967 - accuracy: 0.8138\n",
      "Epoch 184/200\n",
      "768/768 [==============================] - 0s 159us/step - loss: 0.4010 - accuracy: 0.8086\n",
      "Epoch 185/200\n",
      "768/768 [==============================] - 0s 209us/step - loss: 0.3997 - accuracy: 0.8164\n",
      "Epoch 186/200\n",
      "768/768 [==============================] - 0s 148us/step - loss: 0.3938 - accuracy: 0.8203\n",
      "Epoch 187/200\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.4069 - accuracy: 0.8060\n",
      "Epoch 188/200\n",
      "768/768 [==============================] - 0s 194us/step - loss: 0.3894 - accuracy: 0.8268\n",
      "Epoch 189/200\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.3935 - accuracy: 0.8268\n",
      "Epoch 190/200\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.4010 - accuracy: 0.8047\n",
      "Epoch 191/200\n",
      "768/768 [==============================] - 0s 250us/step - loss: 0.3944 - accuracy: 0.8112\n",
      "Epoch 192/200\n",
      "768/768 [==============================] - 0s 139us/step - loss: 0.3967 - accuracy: 0.8164\n",
      "Epoch 193/200\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.3901 - accuracy: 0.8242\n",
      "Epoch 194/200\n",
      "768/768 [==============================] - 0s 242us/step - loss: 0.3926 - accuracy: 0.8138\n",
      "Epoch 195/200\n",
      "768/768 [==============================] - 0s 145us/step - loss: 0.3894 - accuracy: 0.8216\n",
      "Epoch 196/200\n",
      "768/768 [==============================] - 0s 127us/step - loss: 0.3966 - accuracy: 0.8294\n",
      "Epoch 197/200\n",
      "768/768 [==============================] - 0s 185us/step - loss: 0.3976 - accuracy: 0.8177\n",
      "Epoch 198/200\n",
      "768/768 [==============================] - 0s 231us/step - loss: 0.4009 - accuracy: 0.8177\n",
      "Epoch 199/200\n",
      "768/768 [==============================] - 0s 137us/step - loss: 0.3952 - accuracy: 0.8112\n",
      "Epoch 200/200\n",
      "768/768 [==============================] - 0s 148us/step - loss: 0.3840 - accuracy: 0.8255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc7983afcf8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X, Y, nb_epoch= 200, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Evaluate Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the metrics our model with keep note of\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4253038975099723, 0.80078125]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the scores for the model metrics\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 14us/step\n",
      "accuracy: 80.08%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Tie It All Together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load the dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input(X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "X.shape, Y.shape\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, nb_epoch= 150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have built a neural network for the Pima Indians Dataset, what's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8: Evaluate the performance of Deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the decisions of network architecture must be resolved empirically through trial and error and evaluating them on real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Automatic verification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:25: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "514/514 [==============================] - 0s 266us/step - loss: 0.6792 - accuracy: 0.6265 - val_loss: 0.6570 - val_accuracy: 0.6732\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.6664 - accuracy: 0.6401 - val_loss: 0.6506 - val_accuracy: 0.6772\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s 200us/step - loss: 0.6570 - accuracy: 0.6420 - val_loss: 0.6423 - val_accuracy: 0.6772\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s 187us/step - loss: 0.6469 - accuracy: 0.6518 - val_loss: 0.6446 - val_accuracy: 0.6614\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s 149us/step - loss: 0.6481 - accuracy: 0.6693 - val_loss: 0.6328 - val_accuracy: 0.6772\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s 191us/step - loss: 0.6434 - accuracy: 0.6673 - val_loss: 0.6277 - val_accuracy: 0.6929\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s 219us/step - loss: 0.6349 - accuracy: 0.6634 - val_loss: 0.6216 - val_accuracy: 0.7008\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s 144us/step - loss: 0.6269 - accuracy: 0.6848 - val_loss: 0.6167 - val_accuracy: 0.6890\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s 296us/step - loss: 0.6301 - accuracy: 0.6634 - val_loss: 0.6076 - val_accuracy: 0.6929\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s 266us/step - loss: 0.6265 - accuracy: 0.6537 - val_loss: 0.6037 - val_accuracy: 0.6811\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s 335us/step - loss: 0.6131 - accuracy: 0.6829 - val_loss: 0.6070 - val_accuracy: 0.6575\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s 235us/step - loss: 0.6172 - accuracy: 0.6712 - val_loss: 0.5964 - val_accuracy: 0.6693\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s 219us/step - loss: 0.6186 - accuracy: 0.6673 - val_loss: 0.5912 - val_accuracy: 0.6772\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s 264us/step - loss: 0.6096 - accuracy: 0.7043 - val_loss: 0.5863 - val_accuracy: 0.6969\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s 302us/step - loss: 0.6045 - accuracy: 0.6887 - val_loss: 0.5778 - val_accuracy: 0.7126\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s 334us/step - loss: 0.6043 - accuracy: 0.6809 - val_loss: 0.5752 - val_accuracy: 0.7126\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s 262us/step - loss: 0.6016 - accuracy: 0.6887 - val_loss: 0.5754 - val_accuracy: 0.6850\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s 321us/step - loss: 0.5925 - accuracy: 0.7043 - val_loss: 0.5769 - val_accuracy: 0.7126\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s 301us/step - loss: 0.5827 - accuracy: 0.7160 - val_loss: 0.6112 - val_accuracy: 0.6890\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s 314us/step - loss: 0.6095 - accuracy: 0.6946 - val_loss: 0.5853 - val_accuracy: 0.7008\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s 362us/step - loss: 0.5978 - accuracy: 0.6965 - val_loss: 0.5690 - val_accuracy: 0.7047\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s 349us/step - loss: 0.5888 - accuracy: 0.7179 - val_loss: 0.5704 - val_accuracy: 0.7087\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s 312us/step - loss: 0.5872 - accuracy: 0.6965 - val_loss: 0.5739 - val_accuracy: 0.7008\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s 192us/step - loss: 0.5892 - accuracy: 0.7101 - val_loss: 0.5689 - val_accuracy: 0.6969\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.5959 - accuracy: 0.6907 - val_loss: 0.5727 - val_accuracy: 0.7008\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s 190us/step - loss: 0.5848 - accuracy: 0.7043 - val_loss: 0.5688 - val_accuracy: 0.7047\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s 151us/step - loss: 0.5723 - accuracy: 0.7257 - val_loss: 0.5751 - val_accuracy: 0.7047\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s 243us/step - loss: 0.5700 - accuracy: 0.7432 - val_loss: 0.5992 - val_accuracy: 0.6693\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s 340us/step - loss: 0.5730 - accuracy: 0.7257 - val_loss: 0.5595 - val_accuracy: 0.7126\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s 343us/step - loss: 0.5682 - accuracy: 0.6984 - val_loss: 0.5623 - val_accuracy: 0.7087\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s 308us/step - loss: 0.5737 - accuracy: 0.7160 - val_loss: 0.5668 - val_accuracy: 0.6969\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s 305us/step - loss: 0.5633 - accuracy: 0.7160 - val_loss: 0.5645 - val_accuracy: 0.7047\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s 320us/step - loss: 0.5620 - accuracy: 0.7218 - val_loss: 0.5742 - val_accuracy: 0.7008\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s 217us/step - loss: 0.5601 - accuracy: 0.7198 - val_loss: 0.5629 - val_accuracy: 0.7126\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s 186us/step - loss: 0.5676 - accuracy: 0.7237 - val_loss: 0.5645 - val_accuracy: 0.7008\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s 306us/step - loss: 0.5568 - accuracy: 0.7335 - val_loss: 0.5625 - val_accuracy: 0.7047\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s 344us/step - loss: 0.5553 - accuracy: 0.7237 - val_loss: 0.5624 - val_accuracy: 0.7008\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s 397us/step - loss: 0.5503 - accuracy: 0.7374 - val_loss: 0.5579 - val_accuracy: 0.6969\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s 353us/step - loss: 0.5548 - accuracy: 0.7374 - val_loss: 0.5519 - val_accuracy: 0.7047\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s 216us/step - loss: 0.5524 - accuracy: 0.7257 - val_loss: 0.5633 - val_accuracy: 0.6929\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s 169us/step - loss: 0.5524 - accuracy: 0.7393 - val_loss: 0.5544 - val_accuracy: 0.7047\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s 198us/step - loss: 0.5473 - accuracy: 0.7335 - val_loss: 0.5808 - val_accuracy: 0.6772\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s 337us/step - loss: 0.5529 - accuracy: 0.7335 - val_loss: 0.5727 - val_accuracy: 0.7047\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s 339us/step - loss: 0.5437 - accuracy: 0.7451 - val_loss: 0.5550 - val_accuracy: 0.7008\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s 310us/step - loss: 0.5451 - accuracy: 0.7315 - val_loss: 0.5524 - val_accuracy: 0.7008\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s 480us/step - loss: 0.5474 - accuracy: 0.7393 - val_loss: 0.5541 - val_accuracy: 0.7047\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s 216us/step - loss: 0.5419 - accuracy: 0.7393 - val_loss: 0.5667 - val_accuracy: 0.7205\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s 269us/step - loss: 0.5487 - accuracy: 0.7412 - val_loss: 0.5560 - val_accuracy: 0.6929\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s 190us/step - loss: 0.5389 - accuracy: 0.7432 - val_loss: 0.5895 - val_accuracy: 0.6732\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s 207us/step - loss: 0.5453 - accuracy: 0.7393 - val_loss: 0.5658 - val_accuracy: 0.7283\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s 220us/step - loss: 0.5346 - accuracy: 0.7471 - val_loss: 0.6094 - val_accuracy: 0.6339\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s 221us/step - loss: 0.5578 - accuracy: 0.7004 - val_loss: 0.5510 - val_accuracy: 0.7087\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s 214us/step - loss: 0.5362 - accuracy: 0.7451 - val_loss: 0.5498 - val_accuracy: 0.7205\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.5368 - accuracy: 0.7529 - val_loss: 0.5493 - val_accuracy: 0.7402\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.5347 - accuracy: 0.7315 - val_loss: 0.5518 - val_accuracy: 0.7126\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.5323 - accuracy: 0.7412 - val_loss: 0.5431 - val_accuracy: 0.7087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s 173us/step - loss: 0.5351 - accuracy: 0.7432 - val_loss: 0.5508 - val_accuracy: 0.7244\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s 218us/step - loss: 0.5355 - accuracy: 0.7237 - val_loss: 0.5480 - val_accuracy: 0.7165\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.5356 - accuracy: 0.7490 - val_loss: 0.5512 - val_accuracy: 0.7402\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s 217us/step - loss: 0.5321 - accuracy: 0.7374 - val_loss: 0.5875 - val_accuracy: 0.6732\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s 144us/step - loss: 0.5314 - accuracy: 0.7354 - val_loss: 0.5518 - val_accuracy: 0.7126\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s 189us/step - loss: 0.5301 - accuracy: 0.7354 - val_loss: 0.5602 - val_accuracy: 0.7047\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.5404 - accuracy: 0.7432 - val_loss: 0.5484 - val_accuracy: 0.7283\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s 161us/step - loss: 0.5273 - accuracy: 0.7588 - val_loss: 0.5443 - val_accuracy: 0.7441\n",
      "Epoch 65/150\n",
      "514/514 [==============================] - 0s 183us/step - loss: 0.5227 - accuracy: 0.7471 - val_loss: 0.5414 - val_accuracy: 0.7283\n",
      "Epoch 66/150\n",
      "514/514 [==============================] - 0s 149us/step - loss: 0.5305 - accuracy: 0.7588 - val_loss: 0.5483 - val_accuracy: 0.7283\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s 182us/step - loss: 0.5278 - accuracy: 0.7451 - val_loss: 0.5624 - val_accuracy: 0.7205\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.5233 - accuracy: 0.7471 - val_loss: 0.5493 - val_accuracy: 0.7323\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s 124us/step - loss: 0.5252 - accuracy: 0.7549 - val_loss: 0.5445 - val_accuracy: 0.7362\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s 171us/step - loss: 0.5197 - accuracy: 0.7393 - val_loss: 0.5497 - val_accuracy: 0.7283\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s 204us/step - loss: 0.5200 - accuracy: 0.7412 - val_loss: 0.5423 - val_accuracy: 0.7323\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s 147us/step - loss: 0.5246 - accuracy: 0.7588 - val_loss: 0.5408 - val_accuracy: 0.7283\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s 217us/step - loss: 0.5202 - accuracy: 0.7529 - val_loss: 0.5386 - val_accuracy: 0.7362\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5138 - accuracy: 0.7588 - val_loss: 0.5446 - val_accuracy: 0.7362\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s 164us/step - loss: 0.5274 - accuracy: 0.7471 - val_loss: 0.5432 - val_accuracy: 0.7362\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5213 - accuracy: 0.7490 - val_loss: 0.5562 - val_accuracy: 0.7323\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.5193 - accuracy: 0.7568 - val_loss: 0.5331 - val_accuracy: 0.7480\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s 212us/step - loss: 0.5127 - accuracy: 0.7646 - val_loss: 0.5345 - val_accuracy: 0.7520\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.5191 - accuracy: 0.7568 - val_loss: 0.5436 - val_accuracy: 0.7244\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s 209us/step - loss: 0.5161 - accuracy: 0.7549 - val_loss: 0.5372 - val_accuracy: 0.7480\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s 177us/step - loss: 0.5140 - accuracy: 0.7490 - val_loss: 0.5360 - val_accuracy: 0.7283\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - ETA: 0s - loss: 0.4919 - accuracy: 0.76 - 0s 201us/step - loss: 0.5198 - accuracy: 0.7471 - val_loss: 0.5482 - val_accuracy: 0.7205\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s 181us/step - loss: 0.5091 - accuracy: 0.7646 - val_loss: 0.5419 - val_accuracy: 0.7205\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.5107 - accuracy: 0.7568 - val_loss: 0.5614 - val_accuracy: 0.6929\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s 166us/step - loss: 0.5222 - accuracy: 0.7471 - val_loss: 0.5416 - val_accuracy: 0.7362\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s 207us/step - loss: 0.5131 - accuracy: 0.7685 - val_loss: 0.5283 - val_accuracy: 0.7598\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s 154us/step - loss: 0.5126 - accuracy: 0.7685 - val_loss: 0.5478 - val_accuracy: 0.6969\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.5127 - accuracy: 0.7626 - val_loss: 0.5344 - val_accuracy: 0.7323\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s 203us/step - loss: 0.5118 - accuracy: 0.7646 - val_loss: 0.5707 - val_accuracy: 0.7283\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s 146us/step - loss: 0.5118 - accuracy: 0.7549 - val_loss: 0.5353 - val_accuracy: 0.7362\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s 213us/step - loss: 0.5016 - accuracy: 0.7665 - val_loss: 0.5365 - val_accuracy: 0.7244\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s 143us/step - loss: 0.5088 - accuracy: 0.7529 - val_loss: 0.5261 - val_accuracy: 0.7520\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s 187us/step - loss: 0.5128 - accuracy: 0.7374 - val_loss: 0.5308 - val_accuracy: 0.7559\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s 144us/step - loss: 0.5111 - accuracy: 0.7607 - val_loss: 0.5339 - val_accuracy: 0.7480\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s 181us/step - loss: 0.5027 - accuracy: 0.7549 - val_loss: 0.5442 - val_accuracy: 0.7323\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s 207us/step - loss: 0.5085 - accuracy: 0.7529 - val_loss: 0.5345 - val_accuracy: 0.7323\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s 135us/step - loss: 0.5038 - accuracy: 0.7704 - val_loss: 0.5255 - val_accuracy: 0.7480\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s 163us/step - loss: 0.5092 - accuracy: 0.7704 - val_loss: 0.5314 - val_accuracy: 0.7520\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s 206us/step - loss: 0.5007 - accuracy: 0.7549 - val_loss: 0.5321 - val_accuracy: 0.7362\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.5012 - accuracy: 0.7607 - val_loss: 0.5589 - val_accuracy: 0.7205\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s 119us/step - loss: 0.5133 - accuracy: 0.7510 - val_loss: 0.5394 - val_accuracy: 0.7402\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s 137us/step - loss: 0.5002 - accuracy: 0.7626 - val_loss: 0.5303 - val_accuracy: 0.7402\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s 167us/step - loss: 0.5051 - accuracy: 0.7510 - val_loss: 0.5192 - val_accuracy: 0.7638\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s 237us/step - loss: 0.5055 - accuracy: 0.7568 - val_loss: 0.5304 - val_accuracy: 0.7677\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.4983 - accuracy: 0.7568 - val_loss: 0.5178 - val_accuracy: 0.7835\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s 138us/step - loss: 0.4979 - accuracy: 0.7549 - val_loss: 0.5286 - val_accuracy: 0.7441\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s 196us/step - loss: 0.4963 - accuracy: 0.7607 - val_loss: 0.5277 - val_accuracy: 0.7323\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s 183us/step - loss: 0.5217 - accuracy: 0.7451 - val_loss: 0.5348 - val_accuracy: 0.7441\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.4984 - accuracy: 0.7568 - val_loss: 0.5418 - val_accuracy: 0.7323\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s 186us/step - loss: 0.5026 - accuracy: 0.7568 - val_loss: 0.5313 - val_accuracy: 0.7402\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s 117us/step - loss: 0.5010 - accuracy: 0.7549 - val_loss: 0.5255 - val_accuracy: 0.7559\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4978 - accuracy: 0.7626 - val_loss: 0.5220 - val_accuracy: 0.7638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s 158us/step - loss: 0.4926 - accuracy: 0.7743 - val_loss: 0.5363 - val_accuracy: 0.7402\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s 179us/step - loss: 0.4960 - accuracy: 0.7432 - val_loss: 0.5310 - val_accuracy: 0.7402\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.5031 - accuracy: 0.7568 - val_loss: 0.5209 - val_accuracy: 0.7520\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s 219us/step - loss: 0.5043 - accuracy: 0.7568 - val_loss: 0.5212 - val_accuracy: 0.7244\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s 157us/step - loss: 0.4937 - accuracy: 0.7821 - val_loss: 0.5192 - val_accuracy: 0.7677\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s 186us/step - loss: 0.4927 - accuracy: 0.7626 - val_loss: 0.5310 - val_accuracy: 0.7402\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s 169us/step - loss: 0.4918 - accuracy: 0.7529 - val_loss: 0.5214 - val_accuracy: 0.7520\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s 207us/step - loss: 0.4944 - accuracy: 0.7568 - val_loss: 0.5279 - val_accuracy: 0.7362\n",
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.4956 - accuracy: 0.7646 - val_loss: 0.5340 - val_accuracy: 0.7402\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s 210us/step - loss: 0.4958 - accuracy: 0.7626 - val_loss: 0.5214 - val_accuracy: 0.7638\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s 166us/step - loss: 0.4941 - accuracy: 0.7763 - val_loss: 0.5143 - val_accuracy: 0.7717\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s 200us/step - loss: 0.4975 - accuracy: 0.7588 - val_loss: 0.5373 - val_accuracy: 0.7441\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s 136us/step - loss: 0.4883 - accuracy: 0.7646 - val_loss: 0.5175 - val_accuracy: 0.7559\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s 212us/step - loss: 0.4937 - accuracy: 0.7626 - val_loss: 0.5446 - val_accuracy: 0.7480\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s 147us/step - loss: 0.4922 - accuracy: 0.7743 - val_loss: 0.5117 - val_accuracy: 0.7638\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s 202us/step - loss: 0.4897 - accuracy: 0.7549 - val_loss: 0.5181 - val_accuracy: 0.7441\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s 172us/step - loss: 0.4863 - accuracy: 0.7549 - val_loss: 0.5223 - val_accuracy: 0.7559\n",
      "Epoch 130/150\n",
      "514/514 [==============================] - 0s 199us/step - loss: 0.4916 - accuracy: 0.7802 - val_loss: 0.5324 - val_accuracy: 0.7559\n",
      "Epoch 131/150\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.4909 - accuracy: 0.7665 - val_loss: 0.5301 - val_accuracy: 0.7244\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s 188us/step - loss: 0.4964 - accuracy: 0.7607 - val_loss: 0.5326 - val_accuracy: 0.7441\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.4925 - accuracy: 0.7646 - val_loss: 0.5161 - val_accuracy: 0.7717\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s 235us/step - loss: 0.4885 - accuracy: 0.7646 - val_loss: 0.5164 - val_accuracy: 0.7559\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s 197us/step - loss: 0.4874 - accuracy: 0.7665 - val_loss: 0.5177 - val_accuracy: 0.7520\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s 160us/step - loss: 0.4807 - accuracy: 0.7646 - val_loss: 0.5199 - val_accuracy: 0.7677\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s 206us/step - loss: 0.4904 - accuracy: 0.7626 - val_loss: 0.5119 - val_accuracy: 0.7598\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s 165us/step - loss: 0.4939 - accuracy: 0.7646 - val_loss: 0.5135 - val_accuracy: 0.7638\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s 162us/step - loss: 0.4896 - accuracy: 0.7568 - val_loss: 0.5078 - val_accuracy: 0.7717\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s 209us/step - loss: 0.4827 - accuracy: 0.7607 - val_loss: 0.5316 - val_accuracy: 0.7362\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s 128us/step - loss: 0.4988 - accuracy: 0.7490 - val_loss: 0.5078 - val_accuracy: 0.7756\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s 123us/step - loss: 0.4898 - accuracy: 0.7665 - val_loss: 0.5102 - val_accuracy: 0.7756\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s 164us/step - loss: 0.4944 - accuracy: 0.7626 - val_loss: 0.5086 - val_accuracy: 0.7756\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s 136us/step - loss: 0.4873 - accuracy: 0.7724 - val_loss: 0.5070 - val_accuracy: 0.7756\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s 159us/step - loss: 0.4813 - accuracy: 0.7724 - val_loss: 0.5078 - val_accuracy: 0.7756\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s 207us/step - loss: 0.4803 - accuracy: 0.7802 - val_loss: 0.5050 - val_accuracy: 0.7874\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.4828 - accuracy: 0.7626 - val_loss: 0.5321 - val_accuracy: 0.7362\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s 208us/step - loss: 0.4801 - accuracy: 0.7568 - val_loss: 0.5091 - val_accuracy: 0.7717\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s 210us/step - loss: 0.4779 - accuracy: 0.7840 - val_loss: 0.5070 - val_accuracy: 0.7795\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s 163us/step - loss: 0.4795 - accuracy: 0.7588 - val_loss: 0.5252 - val_accuracy: 0.7638\n",
      "768/768 [==============================] - 0s 25us/step\n",
      "accuracy: 75.26%\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "# seed = 7\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# load the dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input(X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# X.shape, Y.shape\n",
    "\n",
    "# Create sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model using validation split\n",
    "model.fit(X, Y, validation_split=0.33, nb_epoch= 150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using manual validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "514/514 [==============================] - 0s 238us/step - loss: 0.6888 - accuracy: 0.6206 - val_loss: 0.6822 - val_accuracy: 0.6378\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s 86us/step - loss: 0.6710 - accuracy: 0.6576 - val_loss: 0.6720 - val_accuracy: 0.6378\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s 83us/step - loss: 0.6619 - accuracy: 0.6576 - val_loss: 0.6673 - val_accuracy: 0.6378\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s 96us/step - loss: 0.6573 - accuracy: 0.6576 - val_loss: 0.6589 - val_accuracy: 0.6378\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s 92us/step - loss: 0.6558 - accuracy: 0.6576 - val_loss: 0.6533 - val_accuracy: 0.6378\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s 81us/step - loss: 0.6456 - accuracy: 0.6576 - val_loss: 0.6466 - val_accuracy: 0.6378\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.6420 - accuracy: 0.6576 - val_loss: 0.6423 - val_accuracy: 0.6378\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s 122us/step - loss: 0.6362 - accuracy: 0.6576 - val_loss: 0.6359 - val_accuracy: 0.6378\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s 94us/step - loss: 0.6273 - accuracy: 0.6537 - val_loss: 0.6285 - val_accuracy: 0.6457\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s 94us/step - loss: 0.6183 - accuracy: 0.6576 - val_loss: 0.6258 - val_accuracy: 0.6457\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.6132 - accuracy: 0.6848 - val_loss: 0.6153 - val_accuracy: 0.6614\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.6075 - accuracy: 0.6907 - val_loss: 0.6090 - val_accuracy: 0.7126\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s 128us/step - loss: 0.6049 - accuracy: 0.6926 - val_loss: 0.6067 - val_accuracy: 0.7087\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s 164us/step - loss: 0.5974 - accuracy: 0.6848 - val_loss: 0.5969 - val_accuracy: 0.7008\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s 185us/step - loss: 0.5960 - accuracy: 0.6926 - val_loss: 0.6205 - val_accuracy: 0.6535\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s 183us/step - loss: 0.5905 - accuracy: 0.6965 - val_loss: 0.5936 - val_accuracy: 0.7008\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s 199us/step - loss: 0.5860 - accuracy: 0.6926 - val_loss: 0.6093 - val_accuracy: 0.6693\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s 203us/step - loss: 0.5795 - accuracy: 0.7043 - val_loss: 0.5890 - val_accuracy: 0.7047\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s 197us/step - loss: 0.5905 - accuracy: 0.6946 - val_loss: 0.5896 - val_accuracy: 0.7047\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s 191us/step - loss: 0.5779 - accuracy: 0.7023 - val_loss: 0.6069 - val_accuracy: 0.6575\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s 121us/step - loss: 0.5780 - accuracy: 0.7101 - val_loss: 0.5886 - val_accuracy: 0.6969\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5688 - accuracy: 0.7004 - val_loss: 0.6127 - val_accuracy: 0.6850\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5746 - accuracy: 0.7121 - val_loss: 0.5951 - val_accuracy: 0.6890\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s 84us/step - loss: 0.5727 - accuracy: 0.7140 - val_loss: 0.5913 - val_accuracy: 0.6969\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.5756 - accuracy: 0.7082 - val_loss: 0.5824 - val_accuracy: 0.7087\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s 129us/step - loss: 0.5648 - accuracy: 0.7140 - val_loss: 0.5976 - val_accuracy: 0.6811\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.5686 - accuracy: 0.7043 - val_loss: 0.5803 - val_accuracy: 0.7126\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s 174us/step - loss: 0.5617 - accuracy: 0.7082 - val_loss: 0.5794 - val_accuracy: 0.7205\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5634 - accuracy: 0.7237 - val_loss: 0.5791 - val_accuracy: 0.7087\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s 116us/step - loss: 0.5687 - accuracy: 0.7082 - val_loss: 0.6063 - val_accuracy: 0.6772\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.5604 - accuracy: 0.7315 - val_loss: 0.5876 - val_accuracy: 0.7008\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s 133us/step - loss: 0.5587 - accuracy: 0.7276 - val_loss: 0.5799 - val_accuracy: 0.6929\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s 125us/step - loss: 0.5532 - accuracy: 0.7257 - val_loss: 0.5878 - val_accuracy: 0.7008\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s 123us/step - loss: 0.5518 - accuracy: 0.7237 - val_loss: 0.5805 - val_accuracy: 0.7126\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s 155us/step - loss: 0.5621 - accuracy: 0.7160 - val_loss: 0.5764 - val_accuracy: 0.7244\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s 153us/step - loss: 0.5477 - accuracy: 0.7354 - val_loss: 0.5868 - val_accuracy: 0.7047\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s 115us/step - loss: 0.5489 - accuracy: 0.7218 - val_loss: 0.5920 - val_accuracy: 0.6969\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.5618 - accuracy: 0.7082 - val_loss: 0.5828 - val_accuracy: 0.6969\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5612 - accuracy: 0.7082 - val_loss: 0.5788 - val_accuracy: 0.7205\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5497 - accuracy: 0.7121 - val_loss: 0.5719 - val_accuracy: 0.7323\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s 132us/step - loss: 0.5481 - accuracy: 0.7296 - val_loss: 0.5855 - val_accuracy: 0.7283\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s 133us/step - loss: 0.5417 - accuracy: 0.7276 - val_loss: 0.5709 - val_accuracy: 0.7165\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.5401 - accuracy: 0.7257 - val_loss: 0.5818 - val_accuracy: 0.7047\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s 94us/step - loss: 0.5469 - accuracy: 0.7198 - val_loss: 0.5771 - val_accuracy: 0.7008\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.5386 - accuracy: 0.7237 - val_loss: 0.5790 - val_accuracy: 0.7126\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s 94us/step - loss: 0.5430 - accuracy: 0.7374 - val_loss: 0.6103 - val_accuracy: 0.6811\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s 98us/step - loss: 0.5442 - accuracy: 0.7335 - val_loss: 0.5712 - val_accuracy: 0.7244\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5366 - accuracy: 0.7335 - val_loss: 0.5702 - val_accuracy: 0.7244\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5418 - accuracy: 0.7257 - val_loss: 0.5655 - val_accuracy: 0.7244\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5364 - accuracy: 0.7296 - val_loss: 0.5720 - val_accuracy: 0.7362\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.5368 - accuracy: 0.7198 - val_loss: 0.5794 - val_accuracy: 0.7008\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s 93us/step - loss: 0.5351 - accuracy: 0.7374 - val_loss: 0.5730 - val_accuracy: 0.7165\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s 91us/step - loss: 0.5309 - accuracy: 0.7354 - val_loss: 0.5621 - val_accuracy: 0.7283\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s 92us/step - loss: 0.5374 - accuracy: 0.7451 - val_loss: 0.5817 - val_accuracy: 0.7008\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5401 - accuracy: 0.7374 - val_loss: 0.5777 - val_accuracy: 0.7165\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s 98us/step - loss: 0.5312 - accuracy: 0.7432 - val_loss: 0.5713 - val_accuracy: 0.7126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5226 - accuracy: 0.7393 - val_loss: 0.5711 - val_accuracy: 0.7047\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.5245 - accuracy: 0.7393 - val_loss: 0.5658 - val_accuracy: 0.7323\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s 99us/step - loss: 0.5291 - accuracy: 0.7412 - val_loss: 0.5611 - val_accuracy: 0.7244\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.5267 - accuracy: 0.7374 - val_loss: 0.5619 - val_accuracy: 0.7323\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s 116us/step - loss: 0.5332 - accuracy: 0.7374 - val_loss: 0.5716 - val_accuracy: 0.7165\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s 155us/step - loss: 0.5239 - accuracy: 0.7374 - val_loss: 0.5678 - val_accuracy: 0.7244\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5232 - accuracy: 0.7471 - val_loss: 0.5580 - val_accuracy: 0.7244\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s 136us/step - loss: 0.5212 - accuracy: 0.7490 - val_loss: 0.5585 - val_accuracy: 0.7441\n",
      "Epoch 65/150\n",
      "514/514 [==============================] - 0s 119us/step - loss: 0.5214 - accuracy: 0.7451 - val_loss: 0.5791 - val_accuracy: 0.7126\n",
      "Epoch 66/150\n",
      "514/514 [==============================] - 0s 135us/step - loss: 0.5263 - accuracy: 0.7335 - val_loss: 0.5547 - val_accuracy: 0.7323\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s 124us/step - loss: 0.5162 - accuracy: 0.7529 - val_loss: 0.5636 - val_accuracy: 0.7283\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s 115us/step - loss: 0.5166 - accuracy: 0.7529 - val_loss: 0.5592 - val_accuracy: 0.7402\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.5391 - accuracy: 0.7218 - val_loss: 0.5588 - val_accuracy: 0.7283\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s 120us/step - loss: 0.5311 - accuracy: 0.7315 - val_loss: 0.5553 - val_accuracy: 0.7441\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s 95us/step - loss: 0.5217 - accuracy: 0.7588 - val_loss: 0.5590 - val_accuracy: 0.7283\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s 99us/step - loss: 0.5178 - accuracy: 0.7296 - val_loss: 0.5507 - val_accuracy: 0.7520\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5133 - accuracy: 0.7529 - val_loss: 0.5521 - val_accuracy: 0.7402\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.5170 - accuracy: 0.7432 - val_loss: 0.5509 - val_accuracy: 0.7283\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.5138 - accuracy: 0.7432 - val_loss: 0.5519 - val_accuracy: 0.7441\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5060 - accuracy: 0.7490 - val_loss: 0.5544 - val_accuracy: 0.7362\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.5112 - accuracy: 0.7393 - val_loss: 0.5510 - val_accuracy: 0.7402\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.5059 - accuracy: 0.7451 - val_loss: 0.5672 - val_accuracy: 0.7126\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.5100 - accuracy: 0.7529 - val_loss: 0.5884 - val_accuracy: 0.6929\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.5163 - accuracy: 0.7451 - val_loss: 0.5499 - val_accuracy: 0.7480\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s 114us/step - loss: 0.4983 - accuracy: 0.7646 - val_loss: 0.5672 - val_accuracy: 0.7402\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s 89us/step - loss: 0.5098 - accuracy: 0.7490 - val_loss: 0.5557 - val_accuracy: 0.7323\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s 89us/step - loss: 0.5040 - accuracy: 0.7529 - val_loss: 0.5563 - val_accuracy: 0.7283\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.5058 - accuracy: 0.7471 - val_loss: 0.5611 - val_accuracy: 0.7087\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s 79us/step - loss: 0.4992 - accuracy: 0.7529 - val_loss: 0.5440 - val_accuracy: 0.7480\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s 116us/step - loss: 0.5028 - accuracy: 0.7412 - val_loss: 0.5504 - val_accuracy: 0.7323\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5035 - accuracy: 0.7646 - val_loss: 0.5497 - val_accuracy: 0.7323\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.4974 - accuracy: 0.7432 - val_loss: 0.5545 - val_accuracy: 0.7283\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.5021 - accuracy: 0.7568 - val_loss: 0.5475 - val_accuracy: 0.7323\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.4992 - accuracy: 0.7549 - val_loss: 0.5451 - val_accuracy: 0.7480\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.4990 - accuracy: 0.7646 - val_loss: 0.5644 - val_accuracy: 0.7008\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s 78us/step - loss: 0.5033 - accuracy: 0.7529 - val_loss: 0.5426 - val_accuracy: 0.7402\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s 85us/step - loss: 0.5169 - accuracy: 0.7549 - val_loss: 0.5480 - val_accuracy: 0.7283\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.5006 - accuracy: 0.7568 - val_loss: 0.5422 - val_accuracy: 0.7441\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s 93us/step - loss: 0.4972 - accuracy: 0.7490 - val_loss: 0.5395 - val_accuracy: 0.7441\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.4872 - accuracy: 0.7529 - val_loss: 0.5438 - val_accuracy: 0.7441\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4961 - accuracy: 0.7510 - val_loss: 0.5428 - val_accuracy: 0.7402\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.4911 - accuracy: 0.7588 - val_loss: 0.5400 - val_accuracy: 0.7362\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.4882 - accuracy: 0.7568 - val_loss: 0.5492 - val_accuracy: 0.7008\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s 85us/step - loss: 0.4982 - accuracy: 0.7607 - val_loss: 0.5371 - val_accuracy: 0.7441\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s 93us/step - loss: 0.4879 - accuracy: 0.7607 - val_loss: 0.5348 - val_accuracy: 0.7559\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4877 - accuracy: 0.7626 - val_loss: 0.5420 - val_accuracy: 0.7323\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s 93us/step - loss: 0.4881 - accuracy: 0.7529 - val_loss: 0.5379 - val_accuracy: 0.7520\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.4918 - accuracy: 0.7626 - val_loss: 0.5334 - val_accuracy: 0.7520\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.4893 - accuracy: 0.7704 - val_loss: 0.5326 - val_accuracy: 0.7598\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s 94us/step - loss: 0.4821 - accuracy: 0.7685 - val_loss: 0.5417 - val_accuracy: 0.7205\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.4784 - accuracy: 0.7568 - val_loss: 0.5571 - val_accuracy: 0.7323\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s 84us/step - loss: 0.4834 - accuracy: 0.7665 - val_loss: 0.5540 - val_accuracy: 0.7126\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s 79us/step - loss: 0.4794 - accuracy: 0.7763 - val_loss: 0.5659 - val_accuracy: 0.7402\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s 77us/step - loss: 0.4882 - accuracy: 0.7685 - val_loss: 0.5339 - val_accuracy: 0.7598\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s 82us/step - loss: 0.4768 - accuracy: 0.7607 - val_loss: 0.5359 - val_accuracy: 0.7402\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s 85us/step - loss: 0.4859 - accuracy: 0.7626 - val_loss: 0.5381 - val_accuracy: 0.7205\n",
      "Epoch 113/150\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.4763 - accuracy: 0.7646 - val_loss: 0.5280 - val_accuracy: 0.7677\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s 84us/step - loss: 0.4731 - accuracy: 0.7782 - val_loss: 0.5440 - val_accuracy: 0.7559\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s 85us/step - loss: 0.4740 - accuracy: 0.7782 - val_loss: 0.5553 - val_accuracy: 0.7126\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s 75us/step - loss: 0.4769 - accuracy: 0.7626 - val_loss: 0.5334 - val_accuracy: 0.7480\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s 80us/step - loss: 0.4748 - accuracy: 0.7743 - val_loss: 0.5328 - val_accuracy: 0.7441\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.4756 - accuracy: 0.7685 - val_loss: 0.5465 - val_accuracy: 0.7205\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.4728 - accuracy: 0.7607 - val_loss: 0.5262 - val_accuracy: 0.7717\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.5317 - val_accuracy: 0.7520\n",
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s 88us/step - loss: 0.4669 - accuracy: 0.7860 - val_loss: 0.5311 - val_accuracy: 0.7165\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4674 - accuracy: 0.7840 - val_loss: 0.5314 - val_accuracy: 0.7323\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s 89us/step - loss: 0.4696 - accuracy: 0.7646 - val_loss: 0.5265 - val_accuracy: 0.7677\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s 86us/step - loss: 0.4760 - accuracy: 0.7549 - val_loss: 0.5271 - val_accuracy: 0.7717\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.4657 - accuracy: 0.7743 - val_loss: 0.5239 - val_accuracy: 0.7559\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s 86us/step - loss: 0.4644 - accuracy: 0.7704 - val_loss: 0.5271 - val_accuracy: 0.7402\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.4658 - accuracy: 0.7704 - val_loss: 0.5239 - val_accuracy: 0.7598\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s 96us/step - loss: 0.4621 - accuracy: 0.7899 - val_loss: 0.5441 - val_accuracy: 0.7638\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s 94us/step - loss: 0.4734 - accuracy: 0.7588 - val_loss: 0.5273 - val_accuracy: 0.7441\n",
      "Epoch 130/150\n",
      "514/514 [==============================] - 0s 79us/step - loss: 0.4618 - accuracy: 0.7763 - val_loss: 0.5328 - val_accuracy: 0.7598\n",
      "Epoch 131/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.4624 - accuracy: 0.7529 - val_loss: 0.5277 - val_accuracy: 0.7638\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s 90us/step - loss: 0.4615 - accuracy: 0.7763 - val_loss: 0.5248 - val_accuracy: 0.7795\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.4661 - accuracy: 0.7763 - val_loss: 0.5256 - val_accuracy: 0.7677\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s 88us/step - loss: 0.4613 - accuracy: 0.7840 - val_loss: 0.5367 - val_accuracy: 0.7441\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s 87us/step - loss: 0.4595 - accuracy: 0.7743 - val_loss: 0.5268 - val_accuracy: 0.7480\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.4590 - accuracy: 0.7938 - val_loss: 0.5262 - val_accuracy: 0.7362\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s 127us/step - loss: 0.4579 - accuracy: 0.7782 - val_loss: 0.5424 - val_accuracy: 0.7323\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s 120us/step - loss: 0.4594 - accuracy: 0.7685 - val_loss: 0.5249 - val_accuracy: 0.7480\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s 122us/step - loss: 0.4565 - accuracy: 0.7879 - val_loss: 0.5474 - val_accuracy: 0.7244\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.4599 - accuracy: 0.7724 - val_loss: 0.5400 - val_accuracy: 0.7677\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s 76us/step - loss: 0.4549 - accuracy: 0.7840 - val_loss: 0.5236 - val_accuracy: 0.7638\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.4576 - accuracy: 0.7840 - val_loss: 0.5303 - val_accuracy: 0.7480\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s 81us/step - loss: 0.4563 - accuracy: 0.7802 - val_loss: 0.5241 - val_accuracy: 0.7835\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s 85us/step - loss: 0.4562 - accuracy: 0.7802 - val_loss: 0.5241 - val_accuracy: 0.7520\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.4499 - accuracy: 0.7860 - val_loss: 0.5252 - val_accuracy: 0.7677\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s 84us/step - loss: 0.4666 - accuracy: 0.7549 - val_loss: 0.5250 - val_accuracy: 0.7677\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s 71us/step - loss: 0.4524 - accuracy: 0.7821 - val_loss: 0.5253 - val_accuracy: 0.7677\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s 96us/step - loss: 0.4484 - accuracy: 0.7977 - val_loss: 0.5258 - val_accuracy: 0.7362\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s 92us/step - loss: 0.4505 - accuracy: 0.7782 - val_loss: 0.5190 - val_accuracy: 0.7520\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s 89us/step - loss: 0.4531 - accuracy: 0.7840 - val_loss: 0.5205 - val_accuracy: 0.7835\n",
      "768/768 [==============================] - 0s 11us/step\n",
      "accuracy: 78.39%\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# fix random seed for reproducibility\n",
    "# seed = 7\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# load the dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input(X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# X.shape, Y.shape\n",
    "\n",
    "# Split data into 67% train and 33% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.33, random_state = seed)\n",
    "\n",
    "# Create sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim = 8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model using validation split\n",
    "model.fit(X_train, y_train,  validation_data = (X_test, y_test), nb_epoch= 150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the metrics our model with keep note of\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46860550840695697, 0.7838541865348816]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the scores for the model metrics\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Manual K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# fix random seed for reproducibility\n",
    "# seed = 7\n",
    "# np.random.seed(seed)\n",
    "\n",
    "# load the dataset\n",
    "dataset = np.loadtxt('pima-indians-diabetes.data.csv', delimiter = ',')\n",
    "# split into input(X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.62%\n",
      "accuracy: 74.03%\n",
      "accuracy: 72.73%\n",
      "accuracy: 85.71%\n",
      "accuracy: 76.62%\n",
      "accuracy: 79.22%\n",
      "accuracy: 71.43%\n",
      "accuracy: 70.13%\n",
      "accuracy: 73.68%\n",
      "accuracy: 77.63%\n",
      "75.78% (+/- 4.28%)\n"
     ]
    }
   ],
   "source": [
    "# Define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# Create a list to store cross validation scores\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X,Y):\n",
    "    # Create sequential model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model using validation split\n",
    "    model.fit(X[train], Y[train], epochs= 150, batch_size=10, verbose=0)\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1]*100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" %(np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 9: Keras Models with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Keras Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7539131879806519\n"
     ]
    }
   ],
   "source": [
    "# import modules. for cross-val and keras wrappers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))    \n",
    "    # compile model\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Set random seed\n",
    "# Load data\n",
    "# Split data into X and Y\n",
    "# Create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "# Evaluate using 10 fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter search for deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in minutes: 13.137764040629069\n",
      "Best: 0.748698 using {'batch_size': 5, 'epochs': 150, 'kernel_initializer': 'uniform', 'optimizer': 'adam'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-9b6553bf0eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrid_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%f (%f) with %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# import useful modules\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "start = time.time()\n",
    "# Use our defined model create_model() but create defaults so our grid search can change parameters.\n",
    "def create_model(kernel_initializer= 'uniform', optimizer = 'adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 8, kernel_initializer=kernel_initializer, activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))    \n",
    "    # compile model\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Set random seed\n",
    "# Load data\n",
    "# Split data into X and Y\n",
    "# Create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose = 0)\n",
    "\n",
    "# Grid search epochs, batch_size, and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epoch = np.array([50, 100, 150])\n",
    "batches = np.array([5, 10, 20])\n",
    "# Grid parameters\n",
    "param_grid = dict(optimizer= optimizers, epochs = epoch, batch_size = batches, kernel_initializer=init)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_results = grid.fit(X, Y)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken in minutes: %s\"%((end-start)/60))\n",
    "\n",
    "# summarize results \n",
    "print(\"Best: %f using %s\" % (grid_results.best_score_, grid_results.best_params_))\n",
    "# for params, mean_score, scores in grid_results.cv_results_:\n",
    "#     print(\"%f (%f) with %r\" %(scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the parameters and their results\n",
    "for i in ['mean_test_score', 'std_test_score', 'params']:\n",
    "    print(i,\" : \",grid_results.cv_results_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have gotten the results from our grid searching, we can use these parameters to design a better network and evaluate on it.\n",
    "\n",
    "Best: 0.748698 using {'batch_size': 5, 'epochs': 150, 'kernel_initializer': 'uniform', 'optimizer': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
